- region: eu-frankfurt-1
  compartment_id: ${OCI_COMPARTMENT_ID}
  models:
    ondemand:
      - name: cohere.command-plus-latest
        model_id: cohere.command-plus-latest
        description: "delivers roughly 50% higher throughput and 25% lower latencies as compared to the previous Command R+ version, while keeping the hardware footprint the same."
        "tool_call": True,  
        "stream_tool_call": True,  

      - name: cohere.command-latest
        model_id: cohere.command-latest
        description: "delivers roughly 50% higher throughput and 25% lower latencies as compared to the previous Command R+ version, while keeping the hardware footprint the same."
        "tool_call": True,  
        "stream_tool_call": True,  

      - name: meta.llama-3.3-70b-instruct
        model_id: meta.llama-3.3-70b-instruct
        description: "Model has 70 billion parameters.Accepts text-only inputs and produces text-only outputs.Delivers better performance than both Llama 3.1 70B and Llama 3.2 90B for text tasks.Maximum prompt + response length 128,000 tokens for each run.For on-demand inferencing, the response length is capped at 4,000 tokens for each run."
        "tool_call": True,
        "stream_tool_call": True,
      
      - name: openai.gpt-oss-120b
        model_id: openai.gpt-oss-120b
        description: "gpt-oss-120b"
        "tool_call": True,  
        "stream_tool_call": True, 

      - name: openai.gpt-oss-20b
        model_id: openai.gpt-oss-20b
        description: "gpt-oss-20b"
        "tool_call": True,  
        "stream_tool_call": True,

      - name: google.gemini-2.5-flash
        model_id: google.gemini-2.5-flash
        description: "google.gemini-2.5-flash"
        "tool_call": True,  
        "stream_tool_call": True,

      - name: google.gemini-2.5-flash-lite
        model_id: google.gemini-2.5-flash-lite
        description: "google.gemini-2.5-flash-lite"
        "tool_call": True,  
        "stream_tool_call": True,

      - name: google.gemini-2.5-pro
        model_id: google.gemini-2.5-pro
        description: "google.gemini-2.5-pro"
        "tool_call": True,  
        "stream_tool_call": True,

    embedding:
      - name: cohere.embed-multilingual-v3.0
        model_id: cohere.embed-multilingual-v3.0
        description: "Cohere multilingual embedding model v3.0"
